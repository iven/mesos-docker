#!/usr/bin/env python2.7

import itertools
import json
import logging
import logging.handlers
import os
import re
import signal
import sys
import subprocess
import threading

import mesos
import mesos_pb2

# We have to use executor.start_cleanup_thread() globally
executor = None


def json_pp(thing):
    return json.dumps(thing, indent=2, separators=(',', ': '), sort_keys=True)


class DockerExecutor(mesos.Executor):
    def __init__(self, argv):
        self._driver = None
        self._task = None
        self._task_data = None

        self._argv = argv

        self._container_data = None
        self._image = None
        self._docker_options = None

        self._relative_cpu = None
        self._memory_in_bytes = None
        self._docker_env = None

        self._allocated_ports = None
        self._image_ports = None
        self._port_pairs = None

        self._cid = None
        self._cid_file = None

        self._run_thread = None
        self._cleanup_thread = None

        self._cleanup_lock = threading.RLock()

    @property
    def cid_file(self):
        """File storing container ID."""
        if self._cid_file is None:
            random_hex = os.urandom(8).encode('hex')
            self._cid_file = '/tmp/docker_cid.{}'.format(random_hex)
        return self._cid_file

    @property
    def cid(self):
        """Container ID."""
        if self._cid is None:
            try:
                with open(self.cid_file) as f:
                    self._cid = f.read().strip()
            except Exception, e:
                logging.error('Error reading cidfile')
                logging.exception(e)
        return self._cid

    @property
    def relative_cpu(self):
        if self._relative_cpu is None:
            resources = self._task.resources
            cpus = [r.scalar.value for r in resources if r.name == 'cpus']
            if cpus:
                self._relative_cpu = int(1024 * cpus[0])
        return self._relative_cpu

    @property
    def memory_in_bytes(self):
        if self._memory_in_bytes is None:
            resources = self._task.resources
            megs = [r.scalar.value for r in resources if r.name == 'mem']
            if megs:
                self._memory_in_bytes = int((2**20) * megs[0])
        return self._memory_in_bytes

    @property
    def allocated_ports(self):
        """Ports allocated by user in Marathon."""
        if self._allocated_ports is None:
            range_resources = [_.ranges.range for _ in self._task.resources
                               if _.name == 'ports']
            ranges = itertools.chain(*range_resources)
            # NB: Casting long() to int() so there's no trailing 'L' in later
            #     stringifications. Ports should only ever be shorts, anyways.
            ports = [range(int(_.begin), int(_.end) + 1) for _ in ranges]
            ports = list(itertools.chain(*ports))

            logging.info('Allocated ports: {}'.format(str(ports)))
            self._allocated_ports = ports
        return self._allocated_ports

    @property
    def image_ports(self):
        """Ports exposed in Dockerfile."""
        if self._image_ports is None:
            text = subprocess.check_output(['docker', 'inspect', self.image])
            parsed = json.loads(text)[0]
            config = None
            ports = []
            if 'Config' in parsed:
                config = parsed['Config']
            if 'config' in parsed and config is None:
                config = parsed['config']
            if config:
                exposed = config.get('ExposedPorts', {})
                if exposed and isinstance(exposed, dict):
                    ports = sorted(int(k.split('/')[0]) for k in exposed.keys())
                specs = config.get('PortSpecs', [])
                if specs and isinstance(specs, list):
                    ports = sorted(int(v.split(':')[-1]) for v in specs)
            logging.info('Docker image inner ports: ' + str(ports))
            self._image_ports = ports
        return self._image_ports

    @property
    def port_pairs(self):
        """Allocated port and target port pairs."""
        if self._port_pairs is None:
            port_pairs = itertools.izip_longest(self.allocated_ports,
                                                self.image_ports)
            self._port_pairs = []
            for allocated, target in port_pairs:
                if allocated is None:
                    logging.warning('Too few ports allocated to this image.')
                    break
                if target is None:
                    target = allocated
                self._port_pairs.append((allocated, target))
        return self._port_pairs

    @property
    def task_data(self):
        """Task data send from Marathon, in JSON."""
        if self._task_data is None:
            try:
                data = json.loads(self._task.data)
                logging.info("Task config: \n{}".format(json_pp(data)))
            except Exception, e:
                logging.critical('JSON from framework is rubbish')
                logging.exception(e)
                exit(2)
            else:
                self._task_data = data
        return self._task_data

    @property
    def container_data(self):
        """Container data extracted from self.task_data."""
        if self._container_data is None:
            try:
                container_data = self.task_data['container']
            except:
                logging.critical("No container options specified")
                return None
            else:
                self._container_data = container_data
        return self._container_data

    @property
    def image(self):
        """Docker image name extracted from self.container_data."""
        if self._image is None:
            container_data = self.container_data

            m = re.match(r'^docker:///(.+)$', container_data['image'])
            try:
                self._image = m.group(1)
            except:
                raise ValueError('container.image must be a docker:/// URL')
        return self._image

    @property
    def docker_options(self):
        """Docker runtime options extracted from self.container_data."""
        if self._docker_options is None:
            self._docker_options = self.container_data['options']
        return self._docker_options

    @property
    def docker_env(self):
        """Get all environment varibles exported into Docker container."""
        if self._docker_env is None:
            env = {}
            for i, port in enumerate(self.allocated_ports):
                if port != 0:
                    env['PORT{}'.format(i)] = str(port)
            if 'PORT0' in env:
                env['PORT'] = env['PORT0']
            if 'env' in self.task_data:
                # NB: user-specified PORT* vars override ours
                env.update(self.task_data['env'])
            self._docker_env = env
        return self._docker_env

    @property
    def cleanup_thread(self):
        if self._cleanup_thread is None:
            self._cleanup_thread = threading.Thread(target=self._cleanup)
            self._cleanup_thread.daemon = True
        return self._cleanup_thread

    @property
    def run_thread(self):
        if self._run_thread is None:
            self._run_thread = threading.Thread(target=self._run)
            self._run_thread.daemon = True
        return self._run_thread

    def _pull_image(self):
        try:
            logging.info('Pulling image: {}'.format(self.image))
            subprocess.check_call(['docker', 'pull', self.image])
            logging.info('Done pulling')
        except Exception, e:
            logging.critical('Docker pull failed')
            logging.exception(e)
            return None

    def _generate_command(self):
        cmd = ['docker', 'run', '--cidfile', self.cid_file]

        # Resource limitations
        if self.relative_cpu is not None:
            cmd.extend(['-c', str(self.relative_cpu)])
        if self.memory_in_bytes is not None:
            cmd.extend(['-m', str(self.memory_in_bytes)])

        # Environment variables
        for k, v in self.docker_env.iteritems():
            cmd.extend(['-e', '{}={}'.format(k, v)])

        # Port Mapping
        for allocated, target in self.port_pairs:
            cmd.extend(['-p', '{}:{}'.format(allocated, target)])

        # User specified options
        cmd.extend(self.docker_options)

        # Image name
        cmd.append(self.image)

        cmd.extend(self._argv)

        return cmd

    def _run(self):
        exitcode = 2

        try:
            self._pull_image()
        except:
            logging.critical('Docker image not ready, quiting')
            exit(exitcode)

        finalstate = mesos_pb2.TASK_FAILED
        try:
            cmd = self._generate_command()
            logging.info('Running command: {}'.format(' '.join(cmd)))

            self._send_state(mesos_pb2.TASK_RUNNING)
            proc = subprocess.Popen(cmd)
            proc.wait()

            exitcode = proc.returncode
            logging.info('Container exited with code: %d' % exitcode)
            if proc.returncode == 0:
                finalstate = mesos_pb2.TASK_FINISHED
            elif self.cleanup_thread.ident is not None:
                finalstate = mesos_pb2.TASK_KILLED
                exitcode = 0
            else:
                finalstate = mesos_pb2.TASK_FAILED
        except Exception, e:
            logging.exception(e)
        finally:
            self._send_state(finalstate)
            exit(exitcode)

    def _cleanup(self):
        if not self._cleanup_lock.acquire(blocking=False):
            logging.warning('Already cleaning up, skipping')
            return

        cid = self.cid
        logging.info("Beginning to cleanup container: {}".format(cid))

        if cid is None:
            logging.warning("Cannot cleanup, CID is None")
        else:
            logging.info('Cleaning up container %s' % cid)

            try:
                logging.info('Stopping container')
                subprocess.check_call(['docker', 'stop', '-t=2', cid])
                logging.info('Done stopping container')
            except Exception, e:
                logging.error('Stopping container failed')
                logging.exception(e)

            try:
                logging.info('Removing container')
                subprocess.check_call(['docker', 'rm', cid])
                logging.info('Done removing container')
            except Exception, e:
                logging.error('Removing container failed')
                logging.exception(e)

            subprocess.call(['rm', '-f', self.cid_file])

        self._cleanup_lock.release()

    def _send_state(self, state):
        try:
            update = mesos_pb2.TaskStatus()
            update.task_id.value = self._task.task_id.value
            update.state = state
            self._driver.sendStatusUpdate(update)
        except Exception, e:
            logging.exception(e)

    def start_cleanup_thread(self, block=False):
        if self.cleanup_thread.is_alive():
            logging.warning("Already cleaning up, skipping")
        else:
            self.cleanup_thread.start()

        if block:
            logging.warning("Waiting for cleanup thread to be completed")
            self.cleanup_thread.join()

    # Mesos Executor API methods
    def registered(self, driver, executorInfo, frameworkInfo, slaveInfo):
        logging.info('Registered with Mesos slave')

    def reregistered(driver, slaveInfo):
        logging.info('Reregistered with Mesos slave')

    def disconnected(driver):
        logging.warning('Disconnected from Mesos slave')

    def launchTask(self, driver, task):
        if self._task is not None:
            logging.error('Executor was reused but '
                          'this executor is not reuseable')
            exit(2)
        self._driver = driver
        self._task = task
        logging.info('Task is: %s' % task.task_id.value)
        try:
            self.run_thread.start()
        except Exception, e:
            logging.exception(e)
            self._send_state(mesos_pb2.TASK_FAILED)
            exit(2)

    def killTask(self, driver, task_id):
        if self._task.task_id.value == task_id.value:
            logging.info('Asked to shutdown managed task %s' % task_id.value)
            self.start_cleanup_thread()
        else:
            logging.warning('Asked to shutdown unknown task %s' % task_id.value)

    def shutdown(self, driver):
        self.start_cleanup_thread()


def init_signal_handlers():
    def handler(signum, _):
        logging.info('Exiting due to signal: {}'.format(signum))
        exit(-signum)

    signal.signal(signal.SIGINT, handler)
    signal.signal(signal.SIGTERM, handler)
    signal.signal(signal.SIGABRT, handler)
    signal.signal(signal.SIGPIPE, handler)
    signal.signal(signal.SIGSEGV, handler)


def init_logging():
    logging.basicConfig(
        format="%(asctime)s %(levelname)s[%(process)d]: %(message)s",
        level=logging.DEBUG)


def exit(returncode):
    """Handles signals, passed as negative numbers, and ensures worker
    process is cleaned up if it exists.

    This function shows up in many places but because it's final
    statement is a call to os._exit() we can be sure it is only ever
    called one time.
    """
    try:
        global executor
        executor.start_cleanup_thread(block=True)
    except Exception, e:
        logging.exception(e)
    finally:
        logging.info("Executor terminated")
        os._exit(((-returncode) + 128) if returncode < 0 else returncode)


if __name__ == '__main__':
    init_logging()
    init_signal_handlers()

    global executor
    executor = DockerExecutor(sys.argv[1:])
    driver = mesos.MesosExecutorDriver(executor)
    logging.info('Ready to serve!')

    exit(0 if driver.run() == mesos_pb2.DRIVER_STOPPED else 1)
